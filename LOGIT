> getwd()

#download titanic dataset from kaggle and read into R

training.data.raw <- read.csv('train.csv',header=T,na.strings=c(""))


#how many missing values per column/variable

sapply(training.data.raw,function(x) sum(is.na(x)))

#how many unique values per colum/variable

sapply(training.data.raw, function(x) length(unique(x)))

#use this library for nice view of missing values in dataset
#install.packages("Amelia")

library("Amelia")
missmap(training.data.raw, main = "Missing values vs observed")

#exclude cabin, along with other variables like name etc

data <- subset(training.data.raw,select=c(2,3,5,6,7,8,10,12))

#deal with missing values in age variable

data$Age[is.na(data$Age)] <- mean(data$Age,na.rm=T)

#check how factors are dealt with inR

contrasts(data$Sex)
contrasts(data$Embarked)

#delete missing rows where embarked is n/a
data <- data[!is.na(data$Embarked),]
rownames(data) <- NULL

#DATA IS CLEANED ATTHIS POINT, FITTING PROCESS TO FOLLOW

#divide data into training and test set

train <- data[1:800,]
test <- data[801:889,]

#be sure to specify this is a binomial logit model

model <- glm(Survived ~.,family=binomial(link='logit'),data=train)

#use summary to obtain results of model fitting

summary(model)

#use anova to check variance in model

anova(model, test="Chisq")

#need to get the equivalent of the R2 in linear regression to check the fit of the model. we can use the McF
install.packages("pscl")
library(pscl)
pR2(model)

#now we use our model to predict on the test dataset. we use 'response' so that outut is in the form of 1 or 0 (p(y=1)>.5,1)

fitted.results <- predict(model,newdata=subset(test,select=c(2,3,4,5,6,7,8)),type='response')
fitted.results <- ifelse(fitted.results > 0.5,1,0)

#now we test the accuracy

misClasificError <- mean(fitted.results != test$Survived)
print(paste('Accuracy',1-misClasificError))

#As a last step, we are going to plot the ROC curve and calculate the AUC (area under the curve) 
#which are typical performance measurements for a binary classifier.
install.packages("ROCR")
library(ROCR)
p <- predict(model, newdata=subset(test,select=c(2,3,4,5,6,7,8)), type="response")
pr <- prediction(p, test$Survived)
prf <- performance(pr, measure = "tpr", x.measure = "fpr")
plot(prf)

auc <- performance(pr, measure = "auc")
auc <- auc@y.values[[1]]
auc
